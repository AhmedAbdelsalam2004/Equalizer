import streamlit as st
import numpy as np
import librosa
import soundfile as sf
import io
import plotly.graph_objects as go
import uuid
import json
import os

# ===================================
# DATA LOADING (PRESETS & FFTS)
# ===================================

@st.cache_resource
def load_presets():
    preset_path = os.path.join(os.path.dirname(__file__), "presets.json")
    try:
        with open(preset_path, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}
    except json.JSONDecodeError:
        return {}

@st.cache_resource
def load_precomputed_ffts():
    """Loads the source FFTs generated by save_source_ffts.py"""
    fft_dir = os.path.join(os.path.dirname(__file__), "saved_ffts")
    if not os.path.exists(fft_dir):
        return None
    try:
        metadata_path = os.path.join(fft_dir, "metadata.npy")
        if not os.path.exists(metadata_path):
            return None
            
        metadata = np.load(metadata_path, allow_pickle=True).item()
        fft_sources = []
        for i in range(1, metadata["n_sources"] + 1):
            fft = np.load(os.path.join(fft_dir, f"source_{i}_fft.npy"))
            fft_sources.append(fft)
            
        return {
            "fft_sources": fft_sources,
            "sample_rate": int(metadata["sample_rate"]),
            "max_len": int(metadata["max_len"]),
            "fft_length": int(metadata["fft_length"])
        }
    except Exception as e:
        print(f"Error loading FFTs: {e}")
        return None

PRESETS = load_presets()
PRECOMPUTED_DATA = load_precomputed_ffts()

# Page configuration
st.set_page_config(
    page_title="Signal Equalizer",
    page_icon="üéµ",
    layout="wide"
)

st.markdown("""
<style>
    .main-header { font-size: 2.5rem; color: #1f77b4; text-align: center; margin-bottom: 2rem; }
    .band-container { background-color: #f8f9fa; padding: 1.2rem; border-radius: 10px; margin-bottom: 1rem; border-left: 5px solid #1f77b4; box-shadow: 0 2px 5px rgba(0,0,0,0.05); }
    .stMetric { background-color: #f0f2f6; padding: 10px; border-radius: 5px; text-align: center; }
</style>
""", unsafe_allow_html=True)


# ===================================
# COOLEY‚ÄìTUKEY FFT
# ===================================

def next_power_of_two(n):
    return 1 << (n - 1).bit_length()


def bit_reverse_copy(arr):
    N = len(arr)
    if N <= 1:
        return arr.astype(complex)
    bits = N.bit_length() - 1
    rev_indices = np.zeros(N, dtype=int)
    for i in range(N):
        rev_indices[i] = int(format(i, f'0{bits}b')[::-1], 2)
    return arr[rev_indices].astype(complex)


def cooley_tukey_fft(x):
    N = len(x)
    if N == 1:
        return x.astype(complex)
    X = bit_reverse_copy(x)
    size = 2
    while size <= N:
        half = size // 2
        w_step = np.exp(-2j * np.pi / size)
        for i in range(0, N, size):
            w = 1 + 0j
            for j in range(half):
                even = X[i + j]
                odd = X[i + j + half]
                X[i + j] = even + w * odd
                X[i + j + half] = even - w * odd
                w *= w_step
        size *= 2
    return X


def cooley_tukey_ifft(X):
    N = len(X)
    X_conj = np.conj(X)
    fft_of_conj = cooley_tukey_fft(X_conj)
    return (np.conj(fft_of_conj) / N).real


# ===================================
# TRUE AUDIOGRAM CONVERSION
# ===================================

ISO_FREQS = np.array([125, 250, 500, 1000, 2000, 4000, 8000])
ISO_SPL_AT_0_HL = np.array([45.0, 25.5, 11.5, 7.0, 7.0, 8.5, 12.0])


def spl_to_dB_HL(dB_SPL, freqs):
    ref_spl = np.interp(freqs, ISO_FREQS, ISO_SPL_AT_0_HL, left=ISO_SPL_AT_0_HL[0], right=ISO_SPL_AT_0_HL[-1])
    return dB_SPL - ref_spl


def magnitude_to_dB_SPL(magnitude, sample_rate):
    pressure_pa = magnitude
    pressure_pa = np.clip(pressure_pa, 1e-9, None)
    dB_SPL = 20 * np.log10(pressure_pa / 20e-6)
    return dB_SPL


# ===================================
# DYNAMIC PLOTLY PLOTS
# ===================================

def create_dynamic_fft_plot(fft_data, sample_rate, title, color):
    N = len(fft_data)
    half = N // 2
    magnitude = np.abs(fft_data[:half])
    freqs = np.linspace(0, sample_rate / 2, half)

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=freqs,
        y=magnitude,
        mode='lines',
        line=dict(color=color, width=1.5),
        name=title,
        fill='tozeroy',
        fillcolor=f"rgba{tuple(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4)) + (0.1,)}" if color.startswith('#') else color
    ))
    fig.update_layout(
        title=dict(text=title, font=dict(size=14)),
        xaxis_title="Frequency (Hz)",
        yaxis_title="Magnitude",
        margin=dict(l=20, r=20, t=40, b=20),
        xaxis=dict(showgrid=True, gridcolor='#eee', rangeslider=dict(visible=False)),
        yaxis=dict(showgrid=True, gridcolor='#eee'),
        plot_bgcolor='rgba(0,0,0,0)',
        hovermode="x unified",
        height=300
    )
    return fig


def create_dynamic_audiogram_plot(fft_data, sample_rate, title, color):
    N = len(fft_data)
    half = N // 2
    magnitude = np.abs(fft_data[:half])
    freqs = np.linspace(0, sample_rate / 2, half)

    valid = freqs >= 100
    freqs = freqs[valid]
    magnitude = magnitude[valid]

    if len(freqs) == 0:
        freqs = np.array([100.0])
        magnitude = np.array([1e-9])

    dB_SPL = magnitude_to_dB_SPL(magnitude, sample_rate)
    dB_HL = spl_to_dB_HL(dB_SPL, freqs)
    dB_HL = np.clip(dB_HL, -10, 120)

    standard_freqs = [125, 250, 500, 1000, 2000, 4000, 8000]
    visible_freqs = [f for f in standard_freqs if f <= sample_rate / 2]

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=freqs,
        y=dB_HL,
        mode='lines',
        line=dict(color=color, width=2),
        name=title
    ))
    fig.update_layout(
        title=dict(text=title, font=dict(size=14)),
        xaxis_title="Frequency (Hz)",
        yaxis_title="Hearing Level (dB HL)",
        margin=dict(l=20, r=20, t=40, b=20),
        xaxis=dict(
            type="log",
            tickvals=visible_freqs,
            ticktext=[str(f) for f in visible_freqs],
            showgrid=True,
            gridcolor='#eee',
            range=[np.log10(100), np.log10(min(10000, sample_rate / 2))]
        ),
        yaxis=dict(
            showgrid=True,
            gridcolor='#eee',
            range=[120, -10]
        ),
        plot_bgcolor='rgba(0,0,0,0)',
        hovermode="x unified",
        height=300
    )
    return fig


def create_dynamic_spectrogram(spectrogram, sample_rate, n_fft=1024, hop_length=512, title="Spectrogram (dB SPL)"):
    """Create interactive Plotly spectrogram."""
    times = np.arange(spectrogram.shape[1]) * hop_length / sample_rate
    freqs = np.linspace(0, sample_rate / 2, spectrogram.shape[0])

    fig = go.Figure(data=go.Heatmap(
        z=spectrogram,
        x=times,
        y=freqs,
        colorscale='Viridis',
        zmin=0,
        zmax=120,
        colorbar=dict(title="dB SPL"),
        hovertemplate="Time: %{x:.2f}s<br>Frequency: %{y:.0f} Hz<br>dB SPL: %{z:.1f}<extra></extra>"
    ))
    fig.update_layout(
        title=dict(text=title, font=dict(size=14)),
        xaxis_title="Time (s)",
        yaxis_title="Frequency (Hz)",
        margin=dict(l=20, r=20, t=40, b=20),
        height=300
    )
    return fig

# ===================================
# CUSTOM SPECTROGRAM (STFT)
# ===================================

def custom_stft(signal, n_fft=1024, hop_length=512):
    window = np.hanning(n_fft)
    pad_len = n_fft - (len(signal) - n_fft) % hop_length
    if pad_len < n_fft:
        pad_len += n_fft
    signal_padded = np.pad(signal, (0, pad_len), mode='constant')
    frames = []
    for i in range(0, len(signal_padded) - n_fft + 1, hop_length):
        frame = signal_padded[i:i + n_fft] * window
        frames.append(frame)
    if not frames:
        frames = [np.pad(signal, (0, n_fft - len(signal)), mode='constant') * window]
    fft_frames = []
    for frame in frames:
        N = next_power_of_two(len(frame))
        frame_padded = np.pad(frame, (0, N - len(frame)), mode='constant')
        fft_result = cooley_tukey_fft(frame_padded)
        fft_frames.append(fft_result[:N // 2])
    return np.abs(np.array(fft_frames).T)


def amplitude_to_dB_SPL(S, sample_rate, n_fft=1024):
    scaling = n_fft / 2
    pressure = S / scaling
    pressure = np.clip(pressure, 1e-9, None)
    dB_SPL = 20 * np.log10(pressure / 20e-6)
    return np.clip(dB_SPL, 0, 120)


# ===================================
# SIGNAL PROCESSING FUNCTIONS
# ===================================

def apply_gain_mask_to_fft(fft_data, full_freqs, bands, sample_rate):
    """Old logic: Filters frequency bands. Used for Generic Mode."""
    N = len(fft_data)
    gain_mask = np.ones(N, dtype=np.float32)
    for band in bands:
        f0 = band["freq"]
        gain = band["gain"]
        bw = band["bandwidth"]
        low = max(0, f0 - bw / 2)
        high = min(sample_rate / 2, f0 + bw / 2)
        in_band = (np.abs(full_freqs) >= low) & (np.abs(full_freqs) <= high)
        gain_mask[in_band] *= gain
        
    magnitudes = np.abs(fft_data)
    phases = np.angle(fft_data)
    new_magnitudes = magnitudes * gain_mask
    return new_magnitudes * np.exp(1j * phases)


def apply_linear_subtraction(fft_mix, gains, precomputed_data):
    """New logic: Linearly subtracts/adds source FFTs based on gain."""
    fft_out = fft_mix.copy()
    sources = precomputed_data["fft_sources"]
    n_bins = len(fft_out)
    
    # We map slider 1 -> source 1, slider 2 -> source 2, etc.
    for i, gain in enumerate(gains):
        if i < len(sources):
            src_fft = sources[i]
            
            # Ensure dimensions match
            limit = min(n_bins, len(src_fft))
            
            # Formula: Mix + (Gain - 1.0) * Source
            factor = gain - 1.0
            
            if abs(factor) > 1e-5:
                fft_out[:limit] += factor * src_fft[:limit]
                
    return fft_out


def process_output_fft(modified_fft, original_audio_data, sample_rate):
    """Processes the modified FFT back to audio, calculates new plots, and updates state."""
    
    # Inverse FFT and Truncate
    equalized_full = cooley_tukey_ifft(modified_fft)
    equalized_audio = equalized_full[:len(original_audio_data)]
    st.session_state.equalized_audio = equalized_audio
    st.session_state.eq_applied = True

    # Re-FFT for plotting (padding if necessary)
    N_orig = len(equalized_audio)
    N_pad = next_power_of_two(N_orig)
    eq_padded = np.pad(equalized_audio, (0, N_pad - N_orig),
                       mode='constant') if N_pad > N_orig else equalized_audio
    eq_fft = cooley_tukey_fft(eq_padded)

    # Generate new plots and update session state
    st.session_state.output_fft_linear = create_dynamic_fft_plot(eq_fft, sample_rate, "Output Signal FFT", 'orange')
    st.session_state.output_audiogram = create_dynamic_audiogram_plot(eq_fft, sample_rate,
                                                             "Output Audiogram (dB HL)", 'orange')

    S_output = custom_stft(equalized_audio, n_fft=1024, hop_length=512)
    S_output_dB = amplitude_to_dB_SPL(S_output, sample_rate, n_fft=1024)
    st.session_state.output_spectrogram = create_dynamic_spectrogram(S_output_dB, sample_rate, 1024, 512,
                                                            "Output Signal (dB SPL)")

    return equalized_audio


# ===================================
# Session State
# ===================================

if 'initialized' not in st.session_state:
    st.session_state.audio_data = None
    st.session_state.sample_rate = None
    st.session_state.equalized_audio = None
    st.session_state.fft_data = None
    st.session_state.full_freqs = None
    st.session_state.eq_bands = []
    st.session_state.last_audio_hash = None
    st.session_state.input_fft_linear = None
    st.session_state.input_audiogram = None
    st.session_state.input_spectrogram = None
    st.session_state.output_fft_linear = None
    st.session_state.output_audiogram = None
    st.session_state.output_spectrogram = None
    st.session_state.eq_applied = False
    st.session_state.initialized = True 

# ===================================
# Sidebar
# ===================================

st.markdown('<h1 class="main-header">üéµ Signal Equalizer</h1>', unsafe_allow_html=True)

with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    # Removed "How to Use" expander
        
    freq_scale = st.radio("Display Mode", ["Linear FFT", "Audiogram (dB HL)"], index=0)
    
    # --- Mode Selection with Icons ---
    mode_options = ["Generic Mode", "Musical Instruments Mode", "Animal Sounds Mode", "Human Voices Mode"]
    mode_icons = {
        "Generic Mode": "üõ†Ô∏è Generic Mode",
        "Musical Instruments Mode": "üéª Musical Instruments Mode",
        "Animal Sounds Mode": "ü¶Å Animal Sounds Mode",
        "Human Voices Mode": "üó£Ô∏è Human Voices Mode"
    }
    
    mode = st.selectbox(
        "Select Mode:",
        mode_options,
        format_func=lambda x: mode_icons.get(x, x)
    )

    uploaded_file = st.file_uploader("üìÇ Upload Audio File", type=['wav', 'mp3', 'flac', 'm4a', 'aac'])

# ===================================
# Load & Preprocess (ONCE ONLY)
# ===================================

if uploaded_file is not None:
    file_hash = hash(uploaded_file.getvalue())
    if file_hash != st.session_state.last_audio_hash:
        with io.BytesIO(uploaded_file.getvalue()) as buffer:
            audio_data, sample_rate = librosa.load(buffer, sr=None)

        N_orig = len(audio_data)
        N_pad = next_power_of_two(N_orig)
        audio_padded = np.pad(audio_data, (0, N_pad - N_orig), mode='constant') if N_pad > N_orig else audio_data

        with st.spinner("‚è≥ Analyzing signal..."):
            try:
                fft_data = cooley_tukey_fft(audio_padded)
                full_freqs = np.fft.fftfreq(len(fft_data), d=1 / sample_rate)

                input_fft_linear = create_dynamic_fft_plot(fft_data, sample_rate, "Input Signal FFT", 'steelblue')
                input_audiogram = create_dynamic_audiogram_plot(fft_data, sample_rate, "Input Audiogram (dB HL)",
                                                                'steelblue')

                S_input = custom_stft(audio_data, n_fft=1024, hop_length=512)
                S_input_dB = amplitude_to_dB_SPL(S_input, sample_rate, n_fft=1024)
                input_spectrogram = create_dynamic_spectrogram(S_input_dB, sample_rate, 1024, 512, "Input Signal (dB SPL)")

                st.session_state.audio_data = audio_data
                st.session_state.sample_rate = sample_rate
                st.session_state.fft_data = fft_data
                st.session_state.full_freqs = full_freqs
                st.session_state.equalized_audio = audio_data.copy()
                st.session_state.last_audio_hash = file_hash
                st.session_state.eq_bands = []
                st.session_state.input_fft_linear = input_fft_linear
                st.session_state.input_audiogram = input_audiogram
                st.session_state.input_spectrogram = input_spectrogram
                st.session_state.output_fft_linear = None
                st.session_state.output_audiogram = None
                st.session_state.output_spectrogram = None
                st.session_state.eq_applied = False
            except Exception as e:
                st.error(f"Processing Error: {e}")


# ===================================
# Main Layout - LAYOUT SETUP
# ===================================

# STEP 1: Create the layout columns FIRST
if st.session_state.audio_data is not None:
    col1, col2 = st.columns([1, 1])

    # STEP 2: Render Input Signal IMMEDIATELY into col1
    with col1:
        st.header("üìä Input Signal")
        st.success(f"‚úÖ Loaded: {uploaded_file.name}")
        
        # Removed Sample Rate & Duration Metrics
        
        st.subheader("üéß Input Playback")
        st.audio(uploaded_file, format='audio/wav')
        
        st.subheader("üìâ Signal Visualization")
        if freq_scale == "Linear FFT":
            st.plotly_chart(st.session_state.input_fft_linear, use_container_width=True)
        else:
            st.plotly_chart(st.session_state.input_audiogram, use_container_width=True)


# ===================================
# Equalizer Controls (Process Logic)
# ===================================

st.divider()
st.header("üéõÔ∏è Equalizer Controls")

if st.session_state.audio_data is not None:
    if mode == "Generic Mode":
        st.subheader("üõ†Ô∏è Parametric Equalizer")

        if st.button("‚ûï Add Band"):
            st.session_state.eq_bands.append({
                "id": str(uuid.uuid4()),
                "freq": 1000,
                "gain": 1.0,
                "bandwidth": 200
            })
            st.rerun()

        for idx, band in enumerate(st.session_state.eq_bands, start=1):
            with st.container():
                st.markdown('<div class="band-container">', unsafe_allow_html=True)
                st.markdown(f"**üîπ Band {idx}**")
                freq = st.slider("üéØ Center Frequency (Hz)", 20, st.session_state.sample_rate // 2, int(band["freq"]),
                                 key=f"freq_{band['id']}")
                gain = st.slider("üîä Gain", 0.0, 2.0, float(band["gain"]), key=f"gain_{band['id']}")
                bw = st.slider("üìâ Bandwidth (Hz)", 10, min(5000, st.session_state.sample_rate // 2),
                               int(band["bandwidth"]),
                               key=f"bw_{band['id']}")
                band.update({"freq": freq, "gain": gain, "bandwidth": bw})
                if st.button(f"üóëÔ∏è Delete Band {idx}", key=f"del_{band['id']}"):
                    st.session_state.eq_bands = [b for b in st.session_state.eq_bands if b["id"] != band["id"]]
                    st.rerun()
                st.markdown('</div>', unsafe_allow_html=True)

        # --- Auto-Apply Logic with Spinner ---
        if st.session_state.fft_data is not None and st.session_state.eq_bands:
            with st.spinner("Adjusting frequencies..."):
                modified_fft = apply_gain_mask_to_fft(
                    st.session_state.fft_data,
                    st.session_state.full_freqs,
                    st.session_state.eq_bands,
                    st.session_state.sample_rate
                )
                process_output_fft(modified_fft, st.session_state.audio_data, st.session_state.sample_rate)


    else:
        # --- CUSTOM MODES ---
        st.subheader(f"üéõÔ∏è {mode}")

        if mode not in PRESETS:
            st.warning(f"No preset found for '{mode}'. Check presets.json.")
        else:
            sources = PRESETS[mode]
            num_sources = len(sources)
            cols = st.columns(min(3, num_sources)) 
            
            source_gains = []
            
            for i, source_name in enumerate(sources):
                with cols[i % len(cols)]:
                    gain = st.slider(
                        source_name.capitalize(),
                        0.0, 2.0, 1.0,
                        key=f"preset_{mode}_{source_name}",
                        label_visibility="visible"
                    )
                    source_gains.append(gain)

            # --- Auto-Apply Logic with Spinner ---
            if st.session_state.fft_data is not None:
                with st.spinner("Adjusting frequencies..."):
                    # CHECK: Do we have precomputed FFTs available?
                    if PRECOMPUTED_DATA is not None:
                        # Use NEW Logic: Linear Spectral Subtraction
                        modified_fft = apply_linear_subtraction(
                            st.session_state.fft_data,
                            source_gains,
                            PRECOMPUTED_DATA
                        )
                    else:
                        # FALLBACK: Use OLD Logic (Frequency Bands) if precomputed data missing
                        preset_bands = []
                        g_idx = 0
                        for s_name in sources:
                            g_val = source_gains[g_idx]
                            g_idx += 1
                            for center, bw in sources[s_name]:
                                preset_bands.append({"freq": center, "gain": g_val, "bandwidth": bw})
                        
                        modified_fft = apply_gain_mask_to_fft(
                            st.session_state.fft_data,
                            st.session_state.full_freqs,
                            preset_bands,
                            st.session_state.sample_rate
                        )

                    process_output_fft(modified_fft, st.session_state.audio_data, st.session_state.sample_rate)


else:
    st.info("üëÜ Upload an audio file first to see equalizer controls")


# ===================================
# Main Layout - OUTPUT DISPLAY (Delayed)
# ===================================

# STEP 4: Now that calculations are done, go back and fill col2!
if st.session_state.audio_data is not None:
    with col2:
        st.header("üîä Output Signal")
        if st.session_state.eq_applied:
            st.success("‚úÖ Equalized signal ready!")
            
            # Prepare audio buffer for output playback
            out_buffer = io.BytesIO()
            sf.write(out_buffer, np.clip(st.session_state.equalized_audio, -1, 1), st.session_state.sample_rate,
                     format='WAV')
            out_buffer.seek(0)
            
            st.subheader("üéß Output Playback")
            st.audio(out_buffer, format='audio/wav')
            
            st.subheader("üìâ Signal Visualization")
            if freq_scale == "Linear FFT":
                st.plotly_chart(st.session_state.output_fft_linear, use_container_width=True)
            else:
                st.plotly_chart(st.session_state.output_audiogram, use_container_width=True)
        else:
            st.info("Adjust sliders below to process signal")


# ===================================
# SPECTROGRAM VIEW (DYNAMIC PLOTLY)
# ===================================

st.divider()

if st.session_state.audio_data is not None:
    show_spectrograms = st.checkbox("Toggle Spectrogram View", value=False)
    
    if show_spectrograms:
        st.header("üìà Spectrogram View (dB SPL)")

        spec_col1, spec_col2 = st.columns(2)
        
        with spec_col1:
            st.subheader("Input Spectrogram (dB SPL)")
            st.plotly_chart(st.session_state.input_spectrogram, use_container_width=True)

        with spec_col2:
            st.subheader("Output Spectrogram (dB SPL)")
            if st.session_state.eq_applied and st.session_state.output_spectrogram is not None:
                st.plotly_chart(st.session_state.output_spectrogram, use_container_width=True)
            else:
                st.info("Adjust sliders to see output spectrogram")

st.divider()
st.caption("Signal Equalizer ‚Ä¢ Task 3 DSP")
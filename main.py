import streamlit as st
import numpy as np
import librosa
import soundfile as sf
import io
import plotly.graph_objects as go
import uuid
import json
import os

# ===================================
# DATA LOADING (PRESETS & FFTS)
# ===================================

@st.cache_resource
def load_presets():
    preset_path = os.path.join(os.path.dirname(__file__), "presets.json")
    try:
        with open(preset_path, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}
    except json.JSONDecodeError:
        return {}

@st.cache_resource
def load_precomputed_ffts():
    """Loads the source FFTs generated by save_source_ffts.py"""
    fft_dir = os.path.join(os.path.dirname(__file__), "saved_ffts")
    if not os.path.exists(fft_dir):
        return None
    try:
        metadata_path = os.path.join(fft_dir, "metadata.npy")
        if not os.path.exists(metadata_path):
            return None
            
        metadata = np.load(metadata_path, allow_pickle=True).item()
        fft_sources = []
        for i in range(1, metadata["n_sources"] + 1):
            fft = np.load(os.path.join(fft_dir, f"source_{i}_fft.npy"))
            fft_sources.append(fft)
            
        return {
            "fft_sources": fft_sources,
            "sample_rate": int(metadata["sample_rate"]),
            "max_len": int(metadata["max_len"]),
            "fft_length": int(metadata["fft_length"])
        }
    except Exception as e:
        print(f"Error loading FFTs: {e}")
        return None

PRESETS = load_presets()
PRECOMPUTED_DATA = load_precomputed_ffts()

# Page configuration
st.set_page_config(
    page_title="Signal Equalizer",
    page_icon="üéµ",
    layout="wide"
)

# --- ULTRA-COMPACT CSS STYLING ---
st.markdown("""
<style>
    /* Reduce top padding of the main container */
    .main > div { padding-top: 0.5rem; }
    .block-container { padding-top: 1rem; padding-bottom: 0rem; }
    
    /* Header adjustments */
    .main-header { font-size: 1.5rem; color: #1f77b4; text-align: center; margin-bottom: 0.5rem; margin-top: 0; }
    h1, h2, h3 { margin-top: 0.1rem !important; margin-bottom: 0.1rem !important; }
    
    /* Compact Band Container */
    .band-container { 
        background-color: #f8f9fa; 
        padding: 0.3rem 0.6rem; 
        border-radius: 6px; 
        margin-bottom: 0.2rem; 
        border-left: 3px solid #1f77b4; 
        box-shadow: 0 1px 2px rgba(0,0,0,0.05); 
    }
    
    /* COMPACT SLIDERS */
    .stSlider {
        padding-top: 0rem !important;
        padding-bottom: 0rem !important;
        margin-top: -15px !important;
        margin-bottom: -5px !important;
    }
    
    .stSlider label {
        font-size: 13px !important;
        padding-bottom: 0rem !important;
    }
    
    /* Tighter Widget Spacing */
    div[data-testid="stVerticalBlock"] > div { gap: 0.3rem !important; }
    div[data-testid="column"] { padding: 0rem; }
    
    .stAudio { margin-top: 0rem; margin-bottom: 0.2rem; }
</style>
""", unsafe_allow_html=True)


# ===================================
# COOLEY‚ÄìTUKEY FFT
# ===================================

def next_power_of_two(n):
    return 1 << (n - 1).bit_length()


def bit_reverse_copy(arr):
    N = len(arr)
    if N <= 1:
        return arr.astype(complex)
    bits = N.bit_length() - 1
    rev_indices = np.zeros(N, dtype=int)
    for i in range(N):
        rev_indices[i] = int(format(i, f'0{bits}b')[::-1], 2)
    return arr[rev_indices].astype(complex)


def cooley_tukey_fft(x):
    N = len(x)
    if N == 1:
        return x.astype(complex)
    X = bit_reverse_copy(x)
    size = 2
    while size <= N:
        half = size // 2
        w_step = np.exp(-2j * np.pi / size)
        for i in range(0, N, size):
            w = 1 + 0j
            for j in range(half):
                even = X[i + j]
                odd = X[i + j + half]
                X[i + j] = even + w * odd
                X[i + j + half] = even - w * odd
                w *= w_step
        size *= 2
    return X


def cooley_tukey_ifft(X):
    N = len(X)
    X_conj = np.conj(X)
    fft_of_conj = cooley_tukey_fft(X_conj)
    return (np.conj(fft_of_conj) / N).real


# ===================================
# TRUE AUDIOGRAM CONVERSION
# ===================================

ISO_FREQS = np.array([125, 250, 500, 1000, 2000, 4000, 8000])
ISO_SPL_AT_0_HL = np.array([45.0, 25.5, 11.5, 7.0, 7.0, 8.5, 12.0])


def spl_to_dB_HL(dB_SPL, freqs):
    ref_spl = np.interp(freqs, ISO_FREQS, ISO_SPL_AT_0_HL, left=ISO_SPL_AT_0_HL[0], right=ISO_SPL_AT_0_HL[-1])
    return dB_SPL - ref_spl


def magnitude_to_dB_SPL(magnitude, sample_rate):
    pressure_pa = magnitude
    pressure_pa = np.clip(pressure_pa, 1e-9, None)
    dB_SPL = 20 * np.log10(pressure_pa / 20e-6)
    return dB_SPL


# ===================================
# DYNAMIC PLOTLY PLOTS (COMPACT)
# ===================================

def create_dynamic_fft_plot(fft_data, sample_rate, title, color):
    N = len(fft_data)
    half = N // 2
    magnitude = np.abs(fft_data[:half])
    freqs = np.linspace(0, sample_rate / 2, half)

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=freqs,
        y=magnitude,
        mode='lines',
        line=dict(color=color, width=1.5),
        name=title,
        fill='tozeroy',
        fillcolor=f"rgba{tuple(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4)) + (0.1,)}" if color.startswith('#') else color
    ))
    fig.update_layout(
        title=dict(text=title, font=dict(size=12)),
        xaxis_title="Frequency (Hz)",
        yaxis_title="Magnitude",
        margin=dict(l=35, r=10, t=30, b=10),
        xaxis=dict(showgrid=True, gridcolor='#eee', rangeslider=dict(visible=False)),
        yaxis=dict(showgrid=True, gridcolor='#eee'),
        plot_bgcolor='rgba(0,0,0,0)',
        hovermode="x unified",
        height=220
    )
    return fig


def create_dynamic_audiogram_plot(fft_data, sample_rate, title, color):
    N = len(fft_data)
    half = N // 2
    magnitude = np.abs(fft_data[:half])
    freqs = np.linspace(0, sample_rate / 2, half)

    valid = freqs >= 100
    freqs = freqs[valid]
    magnitude = magnitude[valid]

    if len(freqs) == 0:
        freqs = np.array([100.0])
        magnitude = np.array([1e-9])

    dB_SPL = magnitude_to_dB_SPL(magnitude, sample_rate)
    dB_HL = spl_to_dB_HL(dB_SPL, freqs)
    dB_HL = np.clip(dB_HL, -10, 120)

    standard_freqs = [125, 250, 500, 1000, 2000, 4000, 8000]
    visible_freqs = [f for f in standard_freqs if f <= sample_rate / 2]

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=freqs,
        y=dB_HL,
        mode='lines',
        line=dict(color=color, width=2),
        name=title
    ))
    fig.update_layout(
        title=dict(text=title, font=dict(size=12)),
        xaxis_title="Frequency (Hz)",
        yaxis_title="Hearing Level (dB HL)",
        margin=dict(l=35, r=10, t=30, b=10),
        xaxis=dict(
            type="log",
            tickvals=visible_freqs,
            ticktext=[str(f) for f in visible_freqs],
            showgrid=True,
            gridcolor='#eee',
            range=[np.log10(100), np.log10(min(10000, sample_rate / 2))]
        ),
        yaxis=dict(
            showgrid=True,
            gridcolor='#eee',
            range=[120, -10]
        ),
        plot_bgcolor='rgba(0,0,0,0)',
        hovermode="x unified",
        height=220
    )
    return fig


def create_dynamic_spectrogram(spectrogram, sample_rate, n_fft=1024, hop_length=512, title="Spectrogram (dB SPL)"):
    times = np.arange(spectrogram.shape[1]) * hop_length / sample_rate
    freqs = np.linspace(0, sample_rate / 2, spectrogram.shape[0])

    fig = go.Figure(data=go.Heatmap(
        z=spectrogram,
        x=times,
        y=freqs,
        colorscale='Viridis',
        zmin=0,
        zmax=120,
        colorbar=dict(title="dB SPL"),
        hovertemplate="Time: %{x:.2f}s<br>Frequency: %{y:.0f} Hz<br>dB SPL: %{z:.1f}<extra></extra>"
    ))
    fig.update_layout(
        title=dict(text=title, font=dict(size=12)),
        xaxis_title="Time (s)",
        yaxis_title="Frequency (Hz)",
        margin=dict(l=35, r=10, t=30, b=10),
        height=200
    )
    return fig

# ===================================
# CUSTOM SPECTROGRAM (STFT)
# ===================================

def custom_stft(signal, n_fft=1024, hop_length=512):
    window = np.hanning(n_fft)
    pad_len = n_fft - (len(signal) - n_fft) % hop_length
    if pad_len < n_fft:
        pad_len += n_fft
    signal_padded = np.pad(signal, (0, pad_len), mode='constant')
    frames = []
    for i in range(0, len(signal_padded) - n_fft + 1, hop_length):
        frame = signal_padded[i:i + n_fft] * window
        frames.append(frame)
    if not frames:
        frames = [np.pad(signal, (0, n_fft - len(signal)), mode='constant') * window]
    fft_frames = []
    for frame in frames:
        N = next_power_of_two(len(frame))
        frame_padded = np.pad(frame, (0, N - len(frame)), mode='constant')
        fft_result = cooley_tukey_fft(frame_padded)
        fft_frames.append(fft_result[:N // 2])
    return np.abs(np.array(fft_frames).T)


def amplitude_to_dB_SPL(S, sample_rate, n_fft=1024):
    scaling = n_fft / 2
    pressure = S / scaling
    pressure = np.clip(pressure, 1e-9, None)
    dB_SPL = 20 * np.log10(pressure / 20e-6)
    return np.clip(dB_SPL, 0, 120)


# ===================================
# SIGNAL PROCESSING FUNCTIONS
# ===================================

def apply_gain_mask_to_fft(fft_data, full_freqs, bands, sample_rate):
    N = len(fft_data)
    gain_mask = np.ones(N, dtype=np.float32)
    for band in bands:
        f0 = band["freq"]
        gain = band["gain"]
        bw = band["bandwidth"]
        low = max(0, f0 - bw / 2)
        high = min(sample_rate / 2, f0 + bw / 2)
        in_band = (np.abs(full_freqs) >= low) & (np.abs(full_freqs) <= high)
        gain_mask[in_band] *= gain
        
    magnitudes = np.abs(fft_data)
    phases = np.angle(fft_data)
    new_magnitudes = magnitudes * gain_mask
    return new_magnitudes * np.exp(1j * phases)


def apply_linear_subtraction(fft_mix, gains, precomputed_data):
    fft_out = fft_mix.copy()
    sources = precomputed_data["fft_sources"]
    n_bins = len(fft_out)
    
    for i, gain in enumerate(gains):
        if i < len(sources):
            src_fft = sources[i]
            limit = min(n_bins, len(src_fft))
            factor = gain - 1.0
            
            if abs(factor) > 1e-5:
                fft_out[:limit] += factor * src_fft[:limit]
                
    return fft_out


def process_output_fft(modified_fft, original_audio_data, sample_rate):
    equalized_full = cooley_tukey_ifft(modified_fft)
    equalized_audio = equalized_full[:len(original_audio_data)]
    st.session_state.equalized_audio = equalized_audio
    st.session_state.eq_applied = True

    N_orig = len(equalized_audio)
    N_pad = next_power_of_two(N_orig)
    eq_padded = np.pad(equalized_audio, (0, N_pad - N_orig),
                       mode='constant') if N_pad > N_orig else equalized_audio
    eq_fft = cooley_tukey_fft(eq_padded)

    st.session_state.output_fft_linear = create_dynamic_fft_plot(eq_fft, sample_rate, "Output FFT", 'orange')
    st.session_state.output_audiogram = create_dynamic_audiogram_plot(eq_fft, sample_rate,
                                                             "Output Audiogram", 'orange')

    S_output = custom_stft(equalized_audio, n_fft=1024, hop_length=512)
    S_output_dB = amplitude_to_dB_SPL(S_output, sample_rate, n_fft=1024)
    st.session_state.output_spectrogram = create_dynamic_spectrogram(S_output_dB, sample_rate, 1024, 512,
                                                            "Output Spectrogram")

    return equalized_audio


# ===================================
# Session State
# ===================================

if 'initialized' not in st.session_state:
    st.session_state.audio_data = None
    st.session_state.sample_rate = None
    st.session_state.equalized_audio = None
    st.session_state.fft_data = None
    st.session_state.full_freqs = None
    st.session_state.eq_bands = []
    st.session_state.last_audio_hash = None
    st.session_state.input_fft_linear = None
    st.session_state.input_audiogram = None
    st.session_state.input_spectrogram = None
    st.session_state.output_fft_linear = None
    st.session_state.output_audiogram = None
    st.session_state.output_spectrogram = None
    st.session_state.eq_applied = False
    st.session_state.initialized = True 

# ===================================
# Sidebar
# ===================================

st.markdown('<h1 class="main-header">üéµ Signal Equalizer</h1>', unsafe_allow_html=True)

with st.sidebar:
    st.subheader("‚öôÔ∏è Configuration")
    
    freq_scale = st.radio("Display", ["Linear FFT", "Audiogram (dB HL)"], index=0)
    
    mode_options = ["Generic Mode", "Musical Instruments Mode", "Animal Sounds Mode", "Human Voices Mode"]
    mode_icons = {
        "Generic Mode": "üõ†Ô∏è Generic",
        "Musical Instruments Mode": "üéª Musical Instruments",
        "Animal Sounds Mode": "ü¶Å Animal Sounds",
        "Human Voices Mode": "üó£Ô∏è Human Voices"
    }
    
    mode = st.selectbox(
        "Mode:",
        mode_options,
        format_func=lambda x: mode_icons.get(x, x)
    )

    uploaded_file = st.file_uploader("üìÇ Upload Audio", type=['wav', 'mp3', 'flac'])

# ===================================
# Load & Preprocess (ONCE ONLY)
# ===================================

if uploaded_file is not None:
    file_hash = hash(uploaded_file.getvalue())
    if file_hash != st.session_state.last_audio_hash:
        with io.BytesIO(uploaded_file.getvalue()) as buffer:
            audio_data, sample_rate = librosa.load(buffer, sr=None)

        N_orig = len(audio_data)
        N_pad = next_power_of_two(N_orig)
        audio_padded = np.pad(audio_data, (0, N_pad - N_orig), mode='constant') if N_pad > N_orig else audio_data

        with st.spinner("‚è≥ Analyzing..."):
            try:
                fft_data = cooley_tukey_fft(audio_padded)
                full_freqs = np.fft.fftfreq(len(fft_data), d=1 / sample_rate)

                input_fft_linear = create_dynamic_fft_plot(fft_data, sample_rate, "Input FFT", 'steelblue')
                input_audiogram = create_dynamic_audiogram_plot(fft_data, sample_rate, "Input Audiogram",
                                                                'steelblue')

                S_input = custom_stft(audio_data, n_fft=1024, hop_length=512)
                S_input_dB = amplitude_to_dB_SPL(S_input, sample_rate, n_fft=1024)
                input_spectrogram = create_dynamic_spectrogram(S_input_dB, sample_rate, 1024, 512, "Input Spectrogram")

                st.session_state.audio_data = audio_data
                st.session_state.sample_rate = sample_rate
                st.session_state.fft_data = fft_data
                st.session_state.full_freqs = full_freqs
                st.session_state.equalized_audio = audio_data.copy()
                st.session_state.last_audio_hash = file_hash
                st.session_state.eq_bands = []
                st.session_state.input_fft_linear = input_fft_linear
                st.session_state.input_audiogram = input_audiogram
                st.session_state.input_spectrogram = input_spectrogram
                st.session_state.output_fft_linear = None
                st.session_state.output_audiogram = None
                st.session_state.output_spectrogram = None
                st.session_state.eq_applied = False
            except Exception as e:
                st.error(f"Error: {e}")


# ===================================
# Main Layout - LAYOUT SETUP
# ===================================

if st.session_state.audio_data is not None:
    col1, col2 = st.columns([1, 1])

    # STEP 2: Render Input Signal
    with col1:
        st.markdown("#### üìä Input")
        st.success(f"‚úÖ {uploaded_file.name}")
        
        st.audio(uploaded_file, format='audio/wav')
        
        if freq_scale == "Linear FFT":
            st.plotly_chart(st.session_state.input_fft_linear, use_container_width=True)
        else:
            st.plotly_chart(st.session_state.input_audiogram, use_container_width=True)


# ===================================
# Equalizer Controls
# ===================================

if st.session_state.audio_data is not None:
    st.markdown(f"#### üéõÔ∏è {mode}")

    if mode == "Generic Mode":
        if st.button("‚ûï Add Band"):
            st.session_state.eq_bands.append({
                "id": str(uuid.uuid4()),
                "freq": 1000,
                "gain": 1.0,
                "bandwidth": 200
            })
            st.rerun()

        for idx, band in enumerate(st.session_state.eq_bands, start=1):
            with st.container():
                st.markdown('<div class="band-container">', unsafe_allow_html=True)
                # CHANGE: 3 columns for Generic Mode band sliders
                cols = st.columns([3, 3, 3, 1])
                freq = cols[0].slider(f"Freq (Hz)", 20, st.session_state.sample_rate // 2, int(band["freq"]), key=f"f_{band['id']}")
                gain = cols[1].slider(f"Gain", 0.0, 2.0, float(band["gain"]), key=f"g_{band['id']}")
                bw = cols[2].slider(f"Width", 10, 5000, int(band["bandwidth"]), key=f"b_{band['id']}")
                if cols[3].button("üóëÔ∏è", key=f"d_{band['id']}"):
                    st.session_state.eq_bands = [b for b in st.session_state.eq_bands if b["id"] != band["id"]]
                    st.rerun()
                band.update({"freq": freq, "gain": gain, "bandwidth": bw})
                st.markdown('</div>', unsafe_allow_html=True)

        if st.session_state.fft_data is not None and st.session_state.eq_bands:
            modified_fft = apply_gain_mask_to_fft(
                st.session_state.fft_data,
                st.session_state.full_freqs,
                st.session_state.eq_bands,
                st.session_state.sample_rate
            )
            process_output_fft(modified_fft, st.session_state.audio_data, st.session_state.sample_rate)


    else:
        # CUSTOM MODES
        if mode not in PRESETS:
            st.warning(f"No preset for '{mode}'")
        else:
            sources = PRESETS[mode]
            # CHANGE: Increased to 4 columns for max compactness
            cols = st.columns(4) 
            source_gains = []
            
            for i, source_name in enumerate(sources):
                with cols[i % 4]: # cycle through 4 columns
                    gain = st.slider(
                        source_name.capitalize(),
                        0.0, 2.0, 1.0,
                        key=f"preset_{mode}_{source_name}"
                    )
                    source_gains.append(gain)

            if st.session_state.fft_data is not None:
                if PRECOMPUTED_DATA is not None:
                    modified_fft = apply_linear_subtraction(
                        st.session_state.fft_data,
                        source_gains,
                        PRECOMPUTED_DATA
                    )
                else:
                    preset_bands = []
                    g_idx = 0
                    for s_name in sources:
                        g_val = source_gains[g_idx]
                        g_idx += 1
                        for center, bw in sources[s_name]:
                            preset_bands.append({"freq": center, "gain": g_val, "bandwidth": bw})
                    
                    modified_fft = apply_gain_mask_to_fft(
                        st.session_state.fft_data,
                        st.session_state.full_freqs,
                        preset_bands,
                        st.session_state.sample_rate
                    )

                process_output_fft(modified_fft, st.session_state.audio_data, st.session_state.sample_rate)


else:
    st.info("üëÜ Upload an audio file")


# ===================================
# Main Layout - OUTPUT DISPLAY (Delayed)
# ===================================

if st.session_state.audio_data is not None:
    with col2:
        st.markdown("#### üîä Output")
        if st.session_state.eq_applied:
            st.success("‚úÖ Ready")
            
            out_buffer = io.BytesIO()
            sf.write(out_buffer, np.clip(st.session_state.equalized_audio, -1, 1), st.session_state.sample_rate,
                     format='WAV')
            out_buffer.seek(0)
            
            st.audio(out_buffer, format='audio/wav')
            
            if freq_scale == "Linear FFT":
                st.plotly_chart(st.session_state.output_fft_linear, use_container_width=True)
            else:
                st.plotly_chart(st.session_state.output_audiogram, use_container_width=True)
        else:
            st.info("Adjust sliders")


# ===================================
# SPECTROGRAM VIEW (COMPACT)
# ===================================

if st.session_state.audio_data is not None:
    with st.expander("üìà Spectrogram View", expanded=False):
        spec_col1, spec_col2 = st.columns(2)
        
        with spec_col1:
            st.caption("Input Spectrogram")
            st.plotly_chart(st.session_state.input_spectrogram, use_container_width=True)

        with spec_col2:
            st.caption("Output Spectrogram")
            if st.session_state.eq_applied and st.session_state.output_spectrogram is not None:
                st.plotly_chart(st.session_state.output_spectrogram, use_container_width=True)
            else:
                st.info("Adjust sliders")